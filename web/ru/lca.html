<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <link rel="stylesheet" href="/pandoc.css" type="text/css" />
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h1 id="корневые-деревья">Корневые деревья</h1>
<p>Дерево называется <em>корневым</em>, если оно ориентированно и из какой-то вершины можно попасть во все остальные — такая вершина единственная, и она называется <em>корнем</em>.</p>
<p>Примеры корневых деревьев: * наследование классов в языках программирования (если множественное наследование запрещено), * дерево факторизации числа на простые (в общем случае не уникальное), * иерархия в какой-нибудь компании, * просто множество как-то вложенных объектов (ссылка на крысу-роботягу).</p>
<p>Сегодня мы поговорим о разных задачах на корневых деревьях. Они все бесполезны в реальной жизни, но очень красивые, и поэтому часто встречаются на олимпиадах.</p>
<div class="figure">
<img src="https://raw.githubusercontent.com/e-maxx-eng/e-maxx-eng/master/img/LCA_Euler.png" alt="dfs" /><p class="caption">dfs</p>
</div>
<h2 id="напоминание-dfs">Напоминание: DFS</h2>
<p>Посчитаем для каждой вершины времена входа (<span class="math">\(tin\)</span>) и выхода (<span class="math">\(tout\)</span>) из неё во время эйлерова прохода.</p>
<p>```c++ vector<int> g[maxn]; int p[maxn], tin[maxn], tout[maxn]; int t = 0;</p>
<p>void dfs (int v) { tin[v] = t++; for (int u : g[v]) dfs(u); tout[v] = t; // при выходе из вершины можно тоже счётчик увеличить, но автор не хочет } ```</p>
<p>У этих массивов много полезных свойств: * Вершина <span class="math">\(u\)</span> является предком <span class="math">\(v\)</span> <span class="math">\(\iff tin_v \in [tin_u, tout_u) \)</span>. Эту проверку можно делать за константу. * Два полуинтервала — <span class="math">\([tin_v, tout_v)\)</span> и <span class="math">\([tin_u, tout_u)\)</span> — либо не пересекаются, либо вложены один в другой. * В <span class="math">\(tin\)</span> есть все числа из промежутка от 0 до <span class="math">\(n-1\)</span>. У каждой вершины — свой номер. * Размер поддерева вершины <span class="math">\(v\)</span> (включая саму вершину) равен <span class="math">\(tout_v - tin_v\)</span>. * Если ввести нумерацию вершин, соответствующую <span class="math">\(tin\)</span>-ам, то поддерево вершины — всегда какой-то промежуток в этой нумерации.</p>
<h2 id="запросы-на-поддеревьях">Запросы на поддеревьях</h2>
<p>Последнее свойство на самом деле очень важное. Его можно использовать для обработки разных запросов на поддеревьях, сводя их к запросам на подотрезкам, которые уже можно решать стандартными методами — например, через ДО.</p>
<blockquote>
<p>Есть корневое дерево. Рядом с каждой вершиной записано число. Два типа запросов: прибавить ко всем вершинам на каком-то поддереве число <span class="math">\(x_i\)</span> и найти значение числа у вершины <span class="math">\(v_i\)</span>.</p>
</blockquote>
<p>Давайте запишем все числа у вершин в позиции, соответствующие <span class="math">\(tin\)</span>-ам их вершин. Что такое «прибавить на поддереве» с точки зрения этого массива? Это то же, самое, что прибавить какую-то константу на каком-то подотрезке, а это можно делать <a href="http://sereja.me/a/segtree">какой-нибудь достаточно продвинутой структурой</a>.</p>
<h2 id="запросы-на-уровнях">Запросы на уровнях</h2>
<blockquote>
<p>Дано корневое дерево. Требуется отвечать на запросы нахождения <span class="math">\(d_i\)</span>-того предка вершины <span class="math">\(v_i\)</span> (т. е. вершины-предка, находящейся на расстоянии <span class="math">\(d_i\)</span>).</p>
</blockquote>
<p>Создадим <span class="math">\(h\)</span> векторов, где <span class="math">\(h\)</span> — высота дерева. В каждый вектор добавим все вершины на этой глубине в том порядке, в котором мы в них заходили в dfs. Как следствие, они будут отсортированы по их <span class="math">\(tin\)</span>-ам.</p>
<p>Теперь заметим, что отрезки их поддеревьев — <span class="math">\([tin_v, tout_v)\)</span> — тоже не пересекаются, а значит ещё и отсортированы. Тогда мы можем просто взять <span class="math">\(tin\)</span> вершины-запроса, посмотреть на вектор нужного уровня и сделать бинпоиск по нужному отрезку.</p>
<h2 id="наименьший-общий-предок">Наименьший общий предок</h2>
<p>Очень много задач нам поможет решить следующая вспомогательная задача.</p>
<blockquote>
<p>Дано корневое дерево. Требуется отвечать на запросы нахождения наименьшего общего предка вершин <span class="math">\(u_i\)</span> и <span class="math">\(v_i\)</span>, то есть вершины <span class="math">\(w\)</span>, которая лежит на пути от корня до <span class="math">\(u_i\)</span>, на пути от корня до <span class="math">\(v_i\)</span>, и при этом самую глубокую (нижнюю) из всех таких.</p>
</blockquote>
<p>По-английский эта задача называется <em>Least Common Ancestor</em>. Есть много разных способов её решать, и мы рассмотрим основные.</p>
<div class="figure">
<img src="http://homepages.kcbbs.gen.nz/tonyg/pictures/least-common-ancestor.png" alt="lca" /><p class="caption">lca</p>
</div>
<p>Для лучшего понимания: медленно (за линейное время) это можно делать так:</p>
<p>```c++ bool a (int u, int v) { return tin[u] &lt;= tin[v] &amp;&amp; tin[v] &lt;= tout[u]; }</p>
<p>int lca (int u, int v) { while (!ancestor(u, v)) u = p[u]; return u; } ```</p>
<h2 id="lca-двоичные-подъемы">LCA: двоичные подъемы</h2>
<p>Предпосчитаем для каждой вершины её 1-го предка, 2-го предка, 4-го, и т.д. Сохраним это всё в двумерном массиве <code>up</code> размера <span class="math">\(n \times \lceil \log n \rceil\)</span> — столько точно хватит. В <code>up[v][d]</code> будет храниться предок вершины <span class="math">\(v\)</span> на расстоянии <span class="math">\(2^d\)</span>, а если такой вершины не существует — то корень.</p>
<p>Такой препроцессинг можно выполнить за <span class="math">\(O(n \log n)\)</span>, используя тот факт, что предок на расстоянии <span class="math">\(2^{d+1}\)</span> — это предок на расстоянии <span class="math">\(2^d\)</span> предка на расстоянии <span class="math">\(2^d\)</span>:</p>
<p>```c++ int up[maxn][logn];</p>
<p>void dfs (int v) { for (int l = 1; l &lt; logn; l++) up[v][l] = up[up[v][l-1]][l-1]; tin[v] = t++; for (int u : g[v]) { up[u][0] = v; dfs(u); } tout[v] = t++; } ```</p>
<p>Пусть поступил очередной запрос — пара вершин <span class="math">\((u, v)\)</span>: * Проверим, не является ли одна вершина предком другой — в таком случае она и является результатом. * Иначе, пользуясь массивом <code>up</code>, будем подниматься по предкам одной из них, пока не найдём самую высокую вершину, которая ещё не является предком другой. Следующая за ней будет искомым LCA.</p>
<p>Подробнее про второй пункт. Пусть <span class="math">\(L = \lceil \log n \rceil\)</span>. Присвоим <span class="math">\(i = L\)</span>. Будем уменьшать эту переменную на единицу, пока <code>up[v][i]</code> не перестанет быть предком <span class="math">\(u\)</span> (указатель <code>up[v][i]</code> изначально будет корнем, а затем каждую итерацию спускаться на <span class="math">\(2^i\)</span>). Когда это произойдёт, подвинем указатель на <span class="math">\(2^i\)</span>-го предка <span class="math">\(v\)</span>, и продолжим дальше. Мы можем это делать, потому что два раза прыгать на {2^i} — можно один раз прыгнуть на <span class="math">\(2^{i+1}\)</span>.</p>
<p><code>c++ int lca (int v, int u) {     if (a(v, u)) return v;     if (a(u, v)) return u;     for (int l = logn-1; l &gt;= 0; l--)         if (!ancestor(up[v][l], u))             v = up[v][l];     return up[v][0]; }</code></p>
<h3 id="асимптотика">Асимптотика</h3>
<p>Препроцессинг — <span class="math">\(O(n \log n)\)</span>. Размер массива <code>up</code> ровно такой, и каждый его элемент вычисляется за константу.</p>
<p>Ответ на запрос — <span class="math">\(O(\log n)\)</span>, потому что по сути мы делаем один бинпоиск.</p>
<h2 id="запросы-на-путях">Запросы на путях</h2>
<p>Пусть нас вместо LCA спрашивают, например, о минимуме на произвольном пути (на всех рёбрах записаны какие-то числа).</p>
<p>Мы можем сделать такой же предподсчет, как в методе двоичных подъемов, но хранить вместе с номером <span class="math">\(2^d\)</span>-го предка минимум на соответствующем пути.</p>
<p>Мы знаем, что минимум на пути от <span class="math">\(u\)</span> до <span class="math">\(v\)</span> — это минимум от минимума на пути от <span class="math">\(u\)</span> до <span class="math">\(lca(u, v)\)</span> и от минимума на пути от <span class="math">\(v\)</span> до <span class="math">\(lca(u, v)\)</span>. А каждый минимум — это минимум на всех двоичных подъемах до LCA.</p>
<p><code>c++ int get_min (int v, int u) {     int ans = inf;     for (int l = logn-1; l &gt;= 0; l--)         if (!ancestor(up[v][l], u))             v = up[v][l], ans = min(ans, mn[v][l]);     for (int l = logn-1; l &gt;= 0; l--)         if (!ancestor(up[u][l], v))             u = up[u][l], ans = min(ans, mn[u][l]);     return min({ans, mn[v][0], mn[u][0]}) }</code></p>
<p>Аналогичным образом можно считать сумму, <code>gcd</code>, полиномиальный хэш и много других странных функций на пути, но только в статичном случае (т. е. когда у нас нет обновлений). Для динамического случая существует heavy-light декомпозиция, но она очень сложная.</p>
<h2 id="сведение-к-rmq">Сведение к RMQ</h2>
<p>Другая идея — это пройтись dfs-ом и выписать два массива: глубины вершин и их номера. Выписывать их мы будем как когда будем входить в вершину, так и когда выходить.</p>
<p><img src='https://www.geeksforgeeks.org/wp-content/uploads/eulertour.png' width='500px'></p>
<p>Во втором массиве мы по сути выписали наш проход dfs-а.</p>
<p>Пусть у нас есть запрос: найти LCA вершин <span class="math">\(v\)</span> и <span class="math">\(u\)</span>. Для определенности положим, что <span class="math">\(tin_v &lt; tin_u\)</span>. Посмотрим на наш выписанный путь между тем моментом, когда мы вышли из <span class="math">\(v\)</span> и в первй раз вошли в <span class="math">\(u\)</span>. Где-то на выписанном пути мы должны были прийти в наименьший общий предок, потому что любой простой путь между двумя вершинами в дереве единственный. При этом, мы не поднимались никогда из LCA куда-то выше, а значит LCA — это самая высокая вершина на этом пути.</p>
<p>Получается, что можно найти LCA, просто найдя позицию минимума на отрезке <span class="math">\([tout_v, tin_u]\)</span> в массиве глубин, и посмотрев, какой вершине она соответствует в эйлеровом обходе. Получается, задачу LCA можно свести к RMQ (нахождению минимума на отрезке), что мы <a href="http://sereja.me/a/segtree">уже умеем</a>.</p>
<h3 id="разреженная-таблица">Разреженная таблица</h3>
<p>На практике асимптотику мы особо не улучшили — пока что всё равно требуется <span class="math">\(O(n \log n)\)</span> времени на запрос в ДО, хоть преподсчёт и будет уже линейным. Асимптотику можно улучшить, используя тот факт, что мы решаем static RMQ, то есть у нас нет изменений этого массива.</p>
<p>Помимо ДО, есть более крутая структура, позволяющая отвечать на запрос минимума за <span class="math">\(O(1)\)</span>, но использующая <span class="math">\(O(n \log n)\)</span> препроцессинга (с очень маленькой константой). Подробнее вы можете почитать в <a href="http://sereja.me/a/sparse-table">отдельной статье</a>.</p>
<h2 id="а-наоборот-можно">А наоборот можно?*</h2>
<p><em>Примечание</em>: алгоритм (Фарах-Колтона и Бендера), описаный в этой секции, абсолютно бесполезен на практике, однако очень интересен с теоретической точки зрения.</p>
<p>Интересный с теоретической точки зрения факт: LCA сводится к RMQ без изменения асимптотики, но не наоборот. Почему это так? Потому что на самом деле мы работаем не со всеми массивами целых чисел от 1 до <span class="math">\(n\)</span>, а только с некоторыми — любые два элемента отличаются не более, чем на единицу, потому что они соответствуют либо спуску, либо подъему в dfs. Выясняется, что это ограничение позволяет находить минимум на подобных массивах за константное время работы как на препроцессинг, так и на запрос. Наоборот, к несчатью, свести нельзя.</p>
<p>Сделаем следующее: раз каждые два элемента отличаются на единицу, сопоставим исходнуму массиву глубин булевый массив размера <span class="math">\(n-1\)</span>: единица стоит, если следующее значение больше, единица в противном случае ноль.</p>
<p>Возьмем константу <span class="math">\(k = \lfloor \frac{\log n}{2} \rfloor\)</span>, и разделим на блоки по столько элементов. На каждом блоек посчитаем минимум, а над всеми такими блоками построим sparse table. Всего блоков <span class="math">\(O(\frac{2 n}{\log n})\)</span>, и построение будет работать за линейное время:</p>
<p><span class="math">\[O(\frac{2 n}{\log n} \log \frac{2 n}{\log n}) = O(\frac{2 n}{\log n} (\log 2n - \log \log n)) = O(n)\]</span></p>
<p>Также посчитаем для каждой возможной маски размера <span class="math">\(\frac{\log n}{2}\)</span> минимум на ней — это можно сделать за их количество, помноженное на длину маски а их немного: всего <span class="math">\(\sqrt n\)</span> (ради этого мы и делили логарифм на два).</p>
<p>ОК. Что теперь можно сделать во время запроса? Запрос — это какой-то отрезок. Он включает в себя какие-то последовательные блоки, и сколько-то ячеек слева и справа, не вошедшие ни в какой цельный блок. Для блочной части мы можем сделать запрос в sparse table — он будет работать за константу.</p>
<p>Не-блочная часть хоть и маленькая, но мы всё же заявили, что будем обрабатывать запросы за константу, и сдержим свое слово. Мы возмем левую не-блочуню часть запроса и возьмем оттуда маску — это можно сделать за константу. Тогда минимум на не-блочной части — это минимум на левом блочном элементе минум минимум на не-блочной маски, которую мы предпосчитали.</p>
<p>Чуть более подробно и с реализацией (автор это никогда не кодил и вам не советует) можно почитать <a href="http://e-maxx.ru/algo/lca_linear">у Емакса</a>.</p>
<p>Впрочем, этот алгоритм на практике использовать нецелесообразно: у него слишком большая константа. Слишком много чего нужно считать, чтобы выкинуть этот логарифм из асимптотики.</p>
<p>Важный вывод такой: RMQ более общая задача, чем LCA. <strong>UPD: это неправда, я глупый.</strong></p>
</body>
</html>
