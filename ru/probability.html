<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
  <meta http-equiv="Content-Style-Type" content="text/css" />
  <meta name="generator" content="pandoc" />
  <title></title>
  <style type="text/css">code{white-space: pre;}</style>
  <style type="text/css">
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; }
code > span.dt { color: #902000; }
code > span.dv { color: #40a070; }
code > span.bn { color: #40a070; }
code > span.fl { color: #40a070; }
code > span.ch { color: #4070a0; }
code > span.st { color: #4070a0; }
code > span.co { color: #60a0b0; font-style: italic; }
code > span.ot { color: #007020; }
code > span.al { color: #ff0000; font-weight: bold; }
code > span.fu { color: #06287e; }
code > span.er { color: #ff0000; font-weight: bold; }
  </style>
  <link rel="stylesheet" href="../pandoc.css" type="text/css" />
  <script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML" type="text/javascript"></script>
</head>
<body>
<h1 id="ликбез-по-теорверу">Ликбез по теорверу</h1>
<ul>
<li>Вероятностные распределения</li>
<li>Матожидание и дисперсия</li>
<li>Парадокс дней рождения</li>
<li>Нормальное распределение</li>
<li>Правдоподобие и оценка качества предсказания</li>
<li>Энтропия и оптимальное кодирование</li>
</ul>
<p>Эта статья представляет собой выжимку самых интересных фактов и «больших идей» теорвера, которые обычно рассказывают на курсах статистики, машинного обучения и теории информации.</p>
<p>(Эти строчки позволят нам генерировать распределения и рисовать графики, не обращайте внимание.)</p>
<pre class="sourceCode python"><code class="sourceCode python"><span class="ch">import</span> numpy <span class="ch">as</span> np

<span class="ch">import</span> matplotlib <span class="ch">as</span> plt
%matplotlib inline

<span class="ch">import</span> seaborn <span class="ch">as</span> sns
sns.<span class="dt">set</span>()</code></pre>
<h2 id="матожидание">Матожидание</h2>
<h2 id="дисперсия">Дисперсия</h2>
<p>Какие два числа лучше всего описывают распределение?</p>
<h2 id="нормальное-распределение">Нормальное распределение</h2>
<p>Центральная предельная теорема названа так пафосно вполне обоснованно.</p>
<p>Она говорит, что нам достаточно про каждое слагаемое знать всего два числа — ожидание и дисперсию.</p>
<p><span class="math">\[ f(x) = \frac{1}{2\sqrt{\pi}} e^{-\frac{(x-\mu)^2}{\sigma^2}} \]</span></p>
<p>Доказать это очень трудно. Даже со ссылками на мощные теоремы оно займёт не одну страницу. Обычно доказательство рассказывают в середине второго курса.</p>
<p>Трудно даже доказать, что это распределение, т. е. что <span class="math">\(\int_{-\inf}^\inf f(x) dx = 1\)</span>.</p>
<h2 id="применения">Применения</h2>
<p>Пусть в некоторой стране есть два кандидата в президенты, назовём их Путин и Навальный.</p>
<p>Мы спросили у 1000 случайных избирателей бинарный вопрос, и 510 из них сказали, что будут голосовать за Путина. С какой вероятностью он победит? Теорема говорит, что число голосов, как</p>
<h2 id="линейные-рекурренты">Линейные рекурренты</h2>
<p>Чтобы решать следующие задачи, нам нужно будет использовать следующий факт:</p>
<p>...</p>
<p>Доказательство мы не приведем.</p>
<p>В частности, таким образом получается формула для чисел Фибоначчи.</p>
<p><span class="math">\[ f_n = \ldots \]</span></p>
<p>Кто бы мог подумать, что все эти иррациональности и степени сократятся и вообще дадут целое число?..</p>
<h2 id="классика">Классика</h2>
<p>Парадокс дней рождения.</p>
<p>Это на самом деле очень часто используемый результат. Так можно считать вероятность коллизии хэшей, а также он используется во многих теоретико-числовых алгоритмах, в которых используется предположения (весьма справедливые) о распределении простых чисел.</p>
<p>Пьяница. Человек стоит на краю обрава и идёт в его сторону с вероятностью p. С какой вероятностью он когда-либо в него упадёт?</p>
<p>TODO: история про эстетическое удовольствие, азарт и смысл посещения казино. Казино. Мы приходим в казино с 1000$ и следующим образом проводим там время: ставим по 1$, пока не обанкротимся или не выиграем 1100$. Какая вероятность того, что мы уйдём с деньгами?</p>
<h2 id="принцип-максимального-правдоподобия">Принцип максимального правдоподобия</h2>
<h2 id="энтропия">Энтропия</h2>
<p>Энтропией называется минимальное число бит, которым теоретически возможно сжать сообщение. Эта величина важна, потому что на практике если её можно посчитать, то сжатие с соответствующей кратностью реально достижимо.</p>
<p>Шумный канал.</p>
<p>Пусть у вас есть 1тб данных и два китайских терабайтника, на каждый из которых можно записать столько данных, но каждый бит имеет вероятность 10% записаться на противоположный. Требуется сохранить данные с первого раза без потерь. Совсем без потерь.</p>
<p>Причём это делается почти впритык.</p>
</body>
</html>
