<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Векторизация</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style>
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../pandoc.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link href="data:image/x-icon;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAQAAADZc7J/AAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAAJcEhZcwAACxMAAAsTAQCanBgAAAAHdElNRQfjBggQFxAS4ilBAAACgElEQVRIx52VS0iUYRSGn/8fzbxMIYoRKSZKi2wGwo2FxRQZIlGbaGUF0b52LWbTLlx0W7VyEZiBWkE5mraRRrJFRUwolQw6zQTeuoiU423eFuk0M//nhJ7dd+Z7n/8932HOscgIgU0lR/Cxn3LKgGlijDJIkAgJiywhZMujVo0qrsyIa1St8shWFnmp/IooW0TkV6mMYuRVQCv6X6woIK+QQ16vkPP2M/WZICHVpyGEvCb5vE7olH6bEV6l1R4w3RpQkYoVNJcSWHsLIUt+rTpvLOuSELqihAmwKr8sgZBHE2aX5UKoRmNmDxPyCBtoodLU1m5yaADC9Jr7XkkLoCqNmPAx1eqqnqhAqEHfzB5GVGXTQLUJ/5xZznGcOuAtQbOHahpsfOQ5f5mng8McZAdnsVigkyUTIA8fGjZ561OpuiRJY6oR2qU35iKGbSqc4GU6qObYmstmYIrH5iIq0JIT+17lupU8BVUsVKsvJgdLtgnbxXZOJ091HAU+0W+0YCnGnvRUlCa+42OdbRHiA3CSbtyZ+q85RDMBfcxxjZKUf5uPO4wwzGsaMwFR1JZe1Jx8uuB4mBtC6LJzXLTZDLKYihziM+fJzfjQGfYC/XxMTy8yaDNEOLWBDznAIcdT7aMRiPI0PR1myGacnn+Zd7ygiUIHwEUjuUAnsdR0D+M20E7k7/knt5ki39guN9uAEPeIr6citIPrOsxQiC9hveIuLylkkgXyKUsR/2CAB8yyEzdhJiliN3aCmzwCCwSl3FfzDL9wYZFAuClJAcSZJoELALFKAWVYvVxkdm3NbDRUs0TqUM021jeU15s2w9YXSxKy9dWWRGx6uVpOyObW+x/B+LEV0hF3cAAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxOS0wNi0wOFQxNjoyMzoxNiswMjowMLEfSBUAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTktMDYtMDhUMTY6MjM6MTYrMDI6MDDAQvCpAAAAV3pUWHRSYXcgcHJvZmlsZSB0eXBlIGlwdGMAAHic4/IMCHFWKCjKT8vMSeVSAAMjCy5jCxMjE0uTFAMTIESANMNkAyOzVCDL2NTIxMzEHMQHy4BIoEouAOoXEXTyQjWVAAAAAElFTkSuQmCC" rel="icon" type="image/x-icon" />
  
  <!-- Yandex.Metrika counter -->
  <script type="text/javascript">
     (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
     m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
     (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");
  
     ym(53961409, "init", {
          clickmap:true,
          trackLinks:true,
          accurateTrackBounce:true,
          webvisor:true
     });
  </script>
  <noscript><div><img src="https://mc.yandex.ru/watch/53961409" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
  <!-- /Yandex.Metrika counter -->
  
  <script>
  // index page width
  document.addEventListener("DOMContentLoaded", function(event) {
    document.getElementsByClassName('contents')[0].parentElement.style.width = "860px";
  });
  </script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Векторизация</h1>
</header>
<h1 id="векторизация">Векторизация</h1>
<p>Рассмотрим следующую программу, в которой складывают два массива:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb1-1" title="1"><span class="pp">#pragma GCC optimize(&quot;O3&quot;)</span></a>
<a class="sourceLine" id="cb1-2" title="2"><span class="co">// ^ включает самый &quot;агрессивный&quot; уровень оптимизации</span></a>
<a class="sourceLine" id="cb1-3" title="3"><span class="co">// то же самое, что добавить флаг &quot;-O3&quot; при компиляции из консоли</span></a>
<a class="sourceLine" id="cb1-4" title="4"><span class="pp">#include </span><span class="im">&lt;iostream&gt;</span></a>
<a class="sourceLine" id="cb1-5" title="5"></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="at">const</span> <span class="dt">int</span> n = <span class="fl">1e6</span>;</a>
<a class="sourceLine" id="cb1-7" title="7"><span class="dt">int</span> a[n], b[n];</a>
<a class="sourceLine" id="cb1-8" title="8"></a>
<a class="sourceLine" id="cb1-9" title="9"><span class="dt">int</span> main() {</a>
<a class="sourceLine" id="cb1-10" title="10">    <span class="dt">int</span> s = <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb1-11" title="11">    <span class="co">// сложим всю сумму в &quot;где-то используемую&quot; переменную,</span></a>
<a class="sourceLine" id="cb1-12" title="12">    <span class="co">// иначе компилятор просто вырежет нужный нам кусок кода</span></a>
<a class="sourceLine" id="cb1-13" title="13"></a>
<a class="sourceLine" id="cb1-14" title="14">    <span class="cf">for</span> (<span class="dt">int</span> t = <span class="dv">0</span>; t &lt; <span class="dv">10000</span>; t++)</a>
<a class="sourceLine" id="cb1-15" title="15">        <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++)</a>
<a class="sourceLine" id="cb1-16" title="16">            s += a[i] + b[i];</a>
<a class="sourceLine" id="cb1-17" title="17"></a>
<a class="sourceLine" id="cb1-18" title="18">    <span class="bu">std::</span>cout &lt;&lt; s &lt;&lt; <span class="bu">std::</span>endl;</a>
<a class="sourceLine" id="cb1-19" title="19"></a>
<a class="sourceLine" id="cb1-20" title="20">    <span class="cf">return</span> <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb1-21" title="21">}</a></code></pre></div>
<p>Если скомпилировать этот код под GCC без всяких дополнительных настроек и запустить, он отработает за 1.65 секунды.</p>
<p>Добавим теперь следующую магическую директиву в самое начало программы:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb2-1" title="1"><span class="pp">#pragma GCC target(&quot;avx2&quot;)</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="co">// ...остальное в точности как было</span></a></code></pre></div>
<p>Скомпилировав и запустив при тех же условиях, программа завершается уже за 0.73 секунды. Это более чем в два раза быстрее, при том, что сам код и уровень оптимизации мы не меняли.</p>
<p>Чтобы понять, что здесь происходит, нам нужно сначала разъяснить некоторые особенности работы современных компьютеров. (Знающие ассемблер могут отмотать примерно до ⅓.)</p>
<h2 id="complex-instruction-set-computing">Complex Instruction Set Computing</h2>
<p>Раньше, во времена, когда компьютеры назывались ЭВМ-ами и занимали целую комнату, увеличение производительности происходило в основном за счёт увеличения тактовой частоты. Тактовая частота условно равна количеству инструкций, выполняемому процессором за единицу времени. (На современных процессорах <a href="http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/">это не так</a> — разные инструкции занимают разное время, которое ещё и может зависеть от разных обстоятельств.)</p>
<p>Помимо жесткого <a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D0%BE%D1%80%D0%BE%D1%81%D1%82%D1%8C_%D1%81%D0%B2%D0%B5%D1%82%D0%B0">физического ограничения</a> на максимально возможную тактовую частоту, такой такой подход в какой-то момент просто перестал быть экономически оправданным: прямое увеличение тактовой частоты приводит к в более чем линейному потреблению энергии, и, следовательно, выделению тепла, которое к тому же нужно ещё как-то выводить.</p>
<p>Поэтому вендоры, в погоне за более дешёвым <a href="https://en.wikipedia.org/wiki/FLOPS">флопсом</a> за доллар, пошли по другому пути: стали добавлять более сложные инструкции, которые делают сразу много полезных действий за раз. Но микросхема от добавления новых инструкций сильно усложняется, что может стать критичным во многих других применениях. В связи с этим, все архитектуры стали делиться на два типа:</p>
<ul>
<li><p><a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC</a> (англ. <strong>reduced</strong> instruction set computer), в которых длина кода (идентификатора) самой инструкции ограничена, а значит ограничено и само количество инструкций. Самые первые компьютеры относились к этому типу и могли не иметь даже отдельных инструкций для умножения и деления. Такие процессоры требует меньше транзисторов, и как следствие сами меньше, дешевле и потребляют меньше энергии. Самое популярное семейство архитектур называется <a href="https://en.wikipedia.org/wiki/ARM_architecture">arm</a> и используется почти на всех современных мобильных устройствах.</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">CISC</a> (англ. <strong>complex</strong> instruction set computer), к которому относят всё, что не RISC — в них длина команды не фиксирована, что позволяет поддерживать практически произовльное количество инструкций. Самое популярное семейство архитектур называется <a href="https://en.wikipedia.org/wiki/X86">x86</a> и используется почти на всех современных декстопах и серверах.</p></li>
</ul>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Mips32_addi.svg/370px-Mips32_addi.svg.png" /></p>
<p>Новые инструкции стали добавлять постепенно, причём разные в зависимости от области применения.</p>
<ul>
<li><p>В обычных CPU довольно быстро добавили инструкцию, которая принимает числа <span class="math inline">\((x, y)\)</span> и загружает в регистр данные по адресу <span class="math inline">\(a \cdot x + y\)</span>. Это полезно при индексации массивов — не нужно отдельно индекс считать.</p></li>
<li><p>На графических сопроцессорах появилась отдельная инструкция, которую называют «saxpy» (сокращенно от выражения <code>s += a * x + y</code>), которая полезна, например, при перемножении матриц.</p></li>
<li><p>В последние GPU от Nvidia добавили «tensor core» — отдельную схему, которая перемножает две матрицы <span class="math inline">\(4 \times 4\)</span> и прибавляет к третьей, как бы производя <span class="math inline">\(4 \times 4 \times 4 = 64\)</span> умножений и <span class="math inline">\(4 \times 4 = 16\)</span> сложений за раз, что сильно ускоряет алгоритмы <a href="https://en.wikipedia.org/wiki/Strassen_algorithm">блочного матричного умножения</a>.</p></li>
</ul>
<p>В этой статье мы сфокусируемся на отдельным виде инструкций, которые позволяют выполнять одну и ту же операцию сразу на какой-то последовательности данных. Эта концепция называется <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>-параллелизмом (англ. <em>single instruction, multiple data</em>).</p>
<h2 id="streaming-simd-extensions">Streaming SIMD Extensions</h2>
<p>SSE — это обобщённое называние всех SIMD-инструкций для x86.</p>
<p>Работают они следующим образом. Помимо обычных регистров (самых близких к процессору ячеек памяти, с которыми он непосредственно работает), есть дополнительные, вмещающие не 64, а 128, 256 или даже 512 бит — в зависимости от поддерживаемой версии SSE. В эти регистры загружается последовательные блоки из памяти, над ним производится какая-то последовательность операций, и итоговый результат записывается обратно в память. Сами операции обычно логически разбивают эту булеву последовательность на блоки, например, по 32 бит, и работают уже с ними.</p>
<p>Подобным способом довольно легко получается оптимизировать простые циклы, производящие какие-нибудь независимые друг от друга операции над векторами (массивами) — поэтому сам такой подход называют <em>векторизацией</em>.</p>
<p>Например, какое-нибудь сложение двух int-овых массивов удаётся таким образом соптимизировать в <span class="math inline">\(\frac{512}{32} = 16\)</span> раз, если процессор поддерживает AVX512, а операции <a href="https://algorithmica.org/ru/bitset">битсета</a> — в 512 раз (реализация из STL, <a href="https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/std/bitset#L77">по всей видимости</a>, SSE не использует).</p>
<p>Очень часто SSE используют для работы с действительными числами, и в этой ситуации возникает прямой trade-off между точностью вычислений и скоростью работы: например, вместо double можно использовать float, и тогда в один и тот же регистр поместится в два раза больше чисел. По этой причине в последнее время стали развиваться различные методы <a href="https://en.wikipedia.org/wiki/Quantization">квантизации</a>: перевода исходых данных в какой-то более дискретизированный формат на входе какой-нибудь процедуры (например, <a href="https://github.com/google/gemmlowp">матричного умножения</a>) и восстановления в исходный формат на выходе.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/SIMD.svg/1200px-SIMD.svg.png" /></p>
<p>Конкретный набор инструкций и размеры регистров зависит от вендора и поколения архитектуры. На данный момент (лето 2019 года) <a href="https://www.cpubenchmark.net/market_share.html">большинство процессоров</a> архитектуры x86 производит Intel, поэтому мы сконцентрируемся именно на их наборе инструкций.</p>
<p>Поддержка SIMD-инструкций добавлялись постепенно, сохраняя обратную совместимость. Если третий пентиум в 1999-м году умел работать с регистрами размера 128, то в самых современных i7 есть 512-битные регистры. Автор не является специалистом в проектировании микропроцессоров, но предполагает, то регистры больше 64 байт (512 бит) появятся не скоро, потому что это уже больше размера <a href="https://en.wikipedia.org/wiki/CPU_cache">кэш-линии</a></p>
<p><img src="https://i0.wp.com/www.urtech.ca/wp-content/uploads/2017/11/Intel-mmx-sse-sse2-avx-AVX-512.png" /></p>
<p>Чтобы разработчикам не нужно было предоставлять отдельные оптимизированные бинарники под каждую конкретную архитектуру, информация о поддержке наборов инструкций процессором зашита в ассемблерную инструкцию <code>cpuid</code>, которую можно просто вызвать в рантайме и всё узнать: <a href="https://gist.github.com/hi2p-perim/7855506">например так</a>.</p>
<p>В компиляторе GCC есть встроенная функция <code>__builtin_cpu_supports</code>, которая берёт строчку-название набора инструкций (“sse”, “avx2”, “avx512f” и т. п.) и возвращает целое число — ноль или какую-то степень двойки. Эта функция работает так: входная строка во время компиляции переводится в нужную степень двойки, которая в рантайме просто AND-ится с маской из cpuid и возвращается — всё ради эффективности.</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb3-1" title="1"><span class="pp">#include </span><span class="im">&lt;iostream&gt;</span></a>
<a class="sourceLine" id="cb3-2" title="2"><span class="kw">using</span> <span class="kw">namespace</span> std;</a>
<a class="sourceLine" id="cb3-3" title="3"></a>
<a class="sourceLine" id="cb3-4" title="4"><span class="dt">int</span> main() {</a>
<a class="sourceLine" id="cb3-5" title="5"></a>
<a class="sourceLine" id="cb3-6" title="6">    cout &lt;&lt; <span class="fu">__builtin_cpu_supports</span>(<span class="st">&quot;sse&quot;</span>) &lt;&lt; endl;</a>
<a class="sourceLine" id="cb3-7" title="7">    cout &lt;&lt; <span class="fu">__builtin_cpu_supports</span>(<span class="st">&quot;sse2&quot;</span>) &lt;&lt; endl;</a>
<a class="sourceLine" id="cb3-8" title="8">    cout &lt;&lt; <span class="fu">__builtin_cpu_supports</span>(<span class="st">&quot;avx&quot;</span>) &lt;&lt; endl;</a>
<a class="sourceLine" id="cb3-9" title="9">    cout &lt;&lt; <span class="fu">__builtin_cpu_supports</span>(<span class="st">&quot;avx2&quot;</span>) &lt;&lt; endl;</a>
<a class="sourceLine" id="cb3-10" title="10">    cout &lt;&lt; <span class="fu">__builtin_cpu_supports</span>(<span class="st">&quot;avx512f&quot;</span>) &lt;&lt; endl;</a>
<a class="sourceLine" id="cb3-11" title="11"></a>
<a class="sourceLine" id="cb3-12" title="12">    <span class="cf">return</span> <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb3-13" title="13">}</a></code></pre></div>
<p>Экономя время читателю: сервера CodeForces и большинство онлайн джаджей на момент написания статьи поддерживают AVX2, то есть умеют полноценно работать с 256-битными регистрами.</p>
<h2 id="c-intrinsics">C++ intrinsics</h2>
<p>SSE это те же чистые ассемблерные инструкции. Языки с каким-либо более верхним <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">уровнем абстракции</a> напрямую работать с ними уже не могут. Однако не обязательно писать на чистом ассемблере, чтобы их использовать — разработчики компиляторов уже позаботились об этом за вас и сделали встроенные функции-обёртки, которые называют <em>интринзиками</em> (англ. <em>intrinsic</em> — «внутренний»).</p>
<p>Чтобы их подключить, нужно указать <code>include</code> на соответствующий заголовочный файл, а также сказать компилятору о том, что мы хотим использовать конкретный набор или наборы инструкций. В примере из начала статьи мы сделали именно это, прописав <code>target("avx2")</code> — компилятор получил доступ к более широким регистрам и продвинутым инструкциям для них, и смог соптимизировать программу примерно в два раза (по умолчанию включены 128-битные <code>sse</code> и <code>sse2</code>, поэтому в 2, а не в <span class="math inline">\(\frac{256}{32} = 8\)</span>).</p>
<p>По аналогии с <code>&lt;bits/stdc++.h&gt;</code>, в GCC такой же заголовочный файл <code>&lt;x86intrin.h&gt;</code>, включающий в себя сразу все SSE-интринзики. Шаблон любителя засоренных неймспейсов и избыточно долгой компиляции может начинаться так:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb4-1" title="1"><span class="pp">#pragma GCC optimize(&quot;O3&quot;)</span></a>
<a class="sourceLine" id="cb4-2" title="2"><span class="pp">#pragma GCC target(&quot;avx2&quot;)</span></a>
<a class="sourceLine" id="cb4-3" title="3"></a>
<a class="sourceLine" id="cb4-4" title="4"><span class="pp">#include </span><span class="im">&lt;x86intrin.h&gt;</span></a>
<a class="sourceLine" id="cb4-5" title="5"><span class="pp">#include </span><span class="im">&lt;bits/stdc++.h&gt;</span></a>
<a class="sourceLine" id="cb4-6" title="6"></a>
<a class="sourceLine" id="cb4-7" title="7"><span class="kw">using</span> <span class="kw">namespace</span> std;</a></code></pre></div>
<p>Перейдём теперь к самому синтаксису.</p>
<p>Простой цикл, в котором складывают два массива 64-битных действительных чисел, на SSE-интринзиках будет выглядеть так:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb5-1" title="1"><span class="dt">double</span> a[<span class="dv">100</span>], b[<span class="dv">100</span>], c[<span class="dv">100</span>];</a>
<a class="sourceLine" id="cb5-2" title="2"></a>
<a class="sourceLine" id="cb5-3" title="3"><span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">100</span>; i += <span class="dv">4</span>) {</a>
<a class="sourceLine" id="cb5-4" title="4">    <span class="co">// загрузим два отрезка по 256 бит в свои регистры</span></a>
<a class="sourceLine" id="cb5-5" title="5">    __m256d x = _mm256_loadu_pd(&amp;a[i]);</a>
<a class="sourceLine" id="cb5-6" title="6">    __m256d y = _mm256_loadu_pd(&amp;b[i]);</a>
<a class="sourceLine" id="cb5-7" title="7">    <span class="co">// - 256 означает размер регистров</span></a>
<a class="sourceLine" id="cb5-8" title="8">    <span class="co">// - d означает &quot;double&quot;</span></a>
<a class="sourceLine" id="cb5-9" title="9">    <span class="co">// - pd озанчает &quot;packed double&quot;</span></a>
<a class="sourceLine" id="cb5-10" title="10"></a>
<a class="sourceLine" id="cb5-11" title="11">    <span class="co">// просуммируем числа и положим результат в другой регистр:</span></a>
<a class="sourceLine" id="cb5-12" title="12">    __m256d z = _mm256_add_pd(x, y);</a>
<a class="sourceLine" id="cb5-13" title="13">    <span class="co">// запишем содержимое регистра в память:</span></a>
<a class="sourceLine" id="cb5-14" title="14">    _mm256_storeu_pd(&amp;c[i], z);</a>
<a class="sourceLine" id="cb5-15" title="15">}</a></code></pre></div>
<p>Конвенция именования интринзиков такая же, как самих инструкций, а она такая же, как в ассемблере — то есть максимально короткая и непонятная.</p>
<p>Большинство команд кодируются как <code>_mm&lt;размерность&gt;_&lt;действие&gt;_&lt;тип&gt;</code>. Например:</p>
<ul>
<li><p><code>_mm_add_epi16</code> — складывает две группы 16-битных <em>extended packed integer</em>, проще говоря <span class="math inline">\(\frac{128}{16} = 8\)</span> <code>short</code>-ов (в инструкциях, где размер регистра не указан, он равен 128).</p></li>
<li><p><code>_mm256_acos_pd</code> — принимает один регистр, содержащий 4 <code>double</code>-ов, и возвращает их арк-косинусы.</p></li>
<li><p><code>_mm256_broadcast_sd</code> — бродкастит (копирует) <code>double</code> из памяти во все четыре слота в регистре.</p></li>
<li><p><code>_mm256_ceil_pd</code> — округляет <code>double</code> к ближайшему <code>int</code>-у вверх.</p></li>
<li><p><code>_mm256_cmpeq_epi32</code> — сравнивает запакованные <code>int</code>-ы и возвращает вектор-маску, в которой для полностью совпавших элементов будет по 32 единицы.</p></li>
<li><p><code>_mm256_blendv_ps</code> — по заданной маске берёт значения либо из первого массива, либо из второго. Часто применяется для замены <code>if</code>-а.</p></li>
</ul>
<p>Комбинаторно получается огромное количество различных функций. Полная документация по ним — <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics Guide</a> — лежит в закладках браузера у каждого уважающего себя performance engineer-а.</p>
<p><strong>Выравнивание.</strong> Отдельно стоит отметить одну делать: операции чтения и записи имеют по две версии — <code>load</code> / <code>loadu</code> и <code>store</code> / <code>storeu</code>. Буква «u» здесь означает «unaligned» (англ. <em>невыровненный</em>). Первые корректно работают только тогда, когда весь считываемый блок помещается на одну кэш-линию (если это не так, то в рантаеме вызвется segfault), в то время как unaligned версия работает всегда и везде.</p>
<p>Это отличие имело очень большое значение на старых компьютерах — если не получалось «выровнять» память, то производительность могла резко упасть (в два и более раз), так как нарушался паттерн последовательного доступа. На современных компьютерах это не так существенно: unaligned версия будет медленне, но в пределах 5%. Вручную «выровнять» память для последовательного чтения через <code>load</code> в случае с массивами можно так:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb6-1" title="1"><span class="kw">alignas</span>(<span class="dv">32</span>) <span class="dt">int</span> a;</a>
<a class="sourceLine" id="cb6-2" title="2"><span class="co">// указатель на начало массива теперь будет кратен 32 байтам,</span></a>
<a class="sourceLine" id="cb6-3" title="3"><span class="co">// то есть размеру sse-блока; теперь любое чтение будет внутри кэш-линии</span></a>
<a class="sourceLine" id="cb6-4" title="4"></a>
<a class="sourceLine" id="cb6-5" title="5"><span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i += <span class="dv">8</span>) {</a>
<a class="sourceLine" id="cb6-6" title="6">    __m256i x = _mm256_load_epi32(&amp;a[i]);</a>
<a class="sourceLine" id="cb6-7" title="7">    <span class="co">// ...</span></a>
<a class="sourceLine" id="cb6-8" title="8">}</a></code></pre></div>
<p><strong>Типизация.</strong> Вообще, загружать и сохранять данные интринзиками и вообще использовать <code>__m</code>-типы на самом деле не обязательно — всё можно сделать и обычным reinterpret_cast-ом. Все данные хранятся в одном и том же формате, и разные типы нужны просто для проверки типов и избежания связанных ошибок.</p>
<p>Некоторые операции есть только для какого-то одного типа, например, тот же <code>_mm256_blendv_ps</code> не имеет аналога для 32-битных <code>int</code>-ов, однако будет работать с ними абсолютно так же. Поэтому to make compiler happy можно применять к ним преобразания типов, которые не будут стоить дополнительных инструкций в рантайме. Они все имеют такой формат: <code>_mm&lt;размерность&gt;_cast&lt;откуда&gt;_&lt;куда&gt;</code>.</p>
<h2 id="нетривиальный-пример">Нетривиальный пример</h2>
<p>Пусть нам зачем-то понадобилось возвести <span class="math inline">\(10^8\)</span> чисел в какие-то степени.</p>
<p>Код для тестирования:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb7-1" title="1"><span class="pp">#pragma GCC optimize(&quot;O3&quot;)</span></a>
<a class="sourceLine" id="cb7-2" title="2"><span class="pp">#pragma GCC target(&quot;avx2&quot;)</span></a>
<a class="sourceLine" id="cb7-3" title="3"></a>
<a class="sourceLine" id="cb7-4" title="4"><span class="pp">#include </span><span class="im">&lt;x86intrin.h&gt;</span></a>
<a class="sourceLine" id="cb7-5" title="5"><span class="pp">#include </span><span class="im">&lt;bits/stdc++.h&gt;</span></a>
<a class="sourceLine" id="cb7-6" title="6"></a>
<a class="sourceLine" id="cb7-7" title="7"><span class="kw">using</span> <span class="kw">namespace</span> std;</a>
<a class="sourceLine" id="cb7-8" title="8"></a>
<a class="sourceLine" id="cb7-9" title="9"><span class="kw">typedef</span> <span class="dt">unsigned</span> <span class="dt">long</span> <span class="dt">long</span> ull;</a>
<a class="sourceLine" id="cb7-10" title="10"><span class="kw">typedef</span> __m256i reg;</a>
<a class="sourceLine" id="cb7-11" title="11"></a>
<a class="sourceLine" id="cb7-12" title="12"><span class="at">const</span> <span class="dt">int</span> n = <span class="fl">1e8</span>;</a>
<a class="sourceLine" id="cb7-13" title="13"><span class="kw">alignas</span>(<span class="dv">32</span>) <span class="dt">unsigned</span> bases[n], results[n], powers[n];</a>
<a class="sourceLine" id="cb7-14" title="14"></a>
<a class="sourceLine" id="cb7-15" title="15"><span class="dt">void</span> timeit(<span class="dt">void</span> (*f)()) {</a>
<a class="sourceLine" id="cb7-16" title="16">    <span class="co">// запускает другую функцию и меряет время её исполнения</span></a>
<a class="sourceLine" id="cb7-17" title="17">    <span class="dt">clock_t</span> start = clock();</a>
<a class="sourceLine" id="cb7-18" title="18">    f();</a>
<a class="sourceLine" id="cb7-19" title="19">    cout &lt;&lt; <span class="dt">double</span>(clock() - start) / CLOCKS_PER_SEC &lt;&lt; endl;</a>
<a class="sourceLine" id="cb7-20" title="20"></a>
<a class="sourceLine" id="cb7-21" title="21">    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">10</span>; i++)</a>
<a class="sourceLine" id="cb7-22" title="22">        cout &lt;&lt; results[i] &lt;&lt; <span class="st">&quot; &quot;</span>;</a>
<a class="sourceLine" id="cb7-23" title="23">    cout &lt;&lt; endl;</a>
<a class="sourceLine" id="cb7-24" title="24">}</a>
<a class="sourceLine" id="cb7-25" title="25"></a>
<a class="sourceLine" id="cb7-26" title="26"><span class="dt">int</span> main() {</a>
<a class="sourceLine" id="cb7-27" title="27">    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++) {</a>
<a class="sourceLine" id="cb7-28" title="28">        bases[i] = rand();</a>
<a class="sourceLine" id="cb7-29" title="29">        powers[i] = rand();</a>
<a class="sourceLine" id="cb7-30" title="30">    }</a>
<a class="sourceLine" id="cb7-31" title="31"></a>
<a class="sourceLine" id="cb7-32" title="32">    <span class="co">// timeit(binpow_simple);</span></a>
<a class="sourceLine" id="cb7-33" title="33">    <span class="co">// timeit(binpow_sse);</span></a>
<a class="sourceLine" id="cb7-34" title="34"></a>
<a class="sourceLine" id="cb7-35" title="35">    <span class="cf">return</span> <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb7-36" title="36">}</a></code></pre></div>
<p>В SSE весьма сложно делить <code>int</code>-ы (см. примечания ниже), поэтому будем считать всё по модулю <span class="math inline">\(2^{32}\)</span>, то есть просто переполняя естественным образом <code>unsigned int</code>.</p>
<p>Напишем стандартное итеративное бинарное возведение в степень:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb8-1" title="1"><span class="dt">void</span> binpow_simple() {</a>
<a class="sourceLine" id="cb8-2" title="2">    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++) {</a>
<a class="sourceLine" id="cb8-3" title="3">        <span class="dt">unsigned</span> a = bases[i], p = powers[i];</a>
<a class="sourceLine" id="cb8-4" title="4"></a>
<a class="sourceLine" id="cb8-5" title="5">        <span class="dt">unsigned</span> res = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb8-6" title="6">        <span class="cf">while</span> (p &gt; <span class="dv">0</span>) {</a>
<a class="sourceLine" id="cb8-7" title="7">            <span class="cf">if</span> (p &amp; <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb8-8" title="8">                res = (res * a);</a>
<a class="sourceLine" id="cb8-9" title="9">            a = (a * a);</a>
<a class="sourceLine" id="cb8-10" title="10">            p &gt;&gt;= <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb8-11" title="11">        }</a>
<a class="sourceLine" id="cb8-12" title="12"></a>
<a class="sourceLine" id="cb8-13" title="13">        results[i] = res;</a>
<a class="sourceLine" id="cb8-14" title="14">    }</a>
<a class="sourceLine" id="cb8-15" title="15">}</a></code></pre></div>
<p>Этот код работает за 9.47 секунды.</p>
<p>Теперь попробуем векторизованную версию:</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb9-1" title="1"><span class="dt">void</span> binpow_sse() {</a>
<a class="sourceLine" id="cb9-2" title="2">    <span class="at">const</span> reg ones = _mm256_set_epi32(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>);</a>
<a class="sourceLine" id="cb9-3" title="3">    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i += <span class="dv">8</span>) {</a>
<a class="sourceLine" id="cb9-4" title="4">        reg a = _mm256_load_si256((__m256i*) &amp;bases[i]);</a>
<a class="sourceLine" id="cb9-5" title="5">        reg p = _mm256_load_si256((__m256i*) &amp;powers[i]);</a>
<a class="sourceLine" id="cb9-6" title="6">        reg res = ones;</a>
<a class="sourceLine" id="cb9-7" title="7"></a>
<a class="sourceLine" id="cb9-8" title="8">        <span class="co">// на самом деле, здесь никакого цикла не будет</span></a>
<a class="sourceLine" id="cb9-9" title="9">        <span class="co">// -- компилятор это развернёт в 32 отдельных блока операций</span></a>
<a class="sourceLine" id="cb9-10" title="10">        <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">32</span>; i++) {</a>
<a class="sourceLine" id="cb9-11" title="11">            <span class="co">// чтобы не писать if, посчитаем для каждого элемента его множитель:</span></a>
<a class="sourceLine" id="cb9-12" title="12">            <span class="co">// это либо единица, либо a, в зависимости от значения нижнего бита p</span></a>
<a class="sourceLine" id="cb9-13" title="13"></a>
<a class="sourceLine" id="cb9-14" title="14">            <span class="co">// маски элементов, которые нужно домножать на a:</span></a>
<a class="sourceLine" id="cb9-15" title="15">            reg mask = _mm256_cmpeq_epi32(_mm256_and_si256(p, ones), ones);</a>
<a class="sourceLine" id="cb9-16" title="16">            <span class="co">// эта операция смешивает два вектора по маске:</span></a>
<a class="sourceLine" id="cb9-17" title="17">            reg mul = _mm256_blendv_epi8(ones, a, mask);</a>
<a class="sourceLine" id="cb9-18" title="18"></a>
<a class="sourceLine" id="cb9-19" title="19">            <span class="co">// res *= mul:</span></a>
<a class="sourceLine" id="cb9-20" title="20">            res = _mm256_mullo_epi32(res, mul);</a>
<a class="sourceLine" id="cb9-21" title="21"></a>
<a class="sourceLine" id="cb9-22" title="22">            <span class="co">// a *= a:</span></a>
<a class="sourceLine" id="cb9-23" title="23">            a = _mm256_mullo_epi32(a, a);</a>
<a class="sourceLine" id="cb9-24" title="24"></a>
<a class="sourceLine" id="cb9-25" title="25">            <span class="co">// p &gt;&gt;= 1:</span></a>
<a class="sourceLine" id="cb9-26" title="26">            p = _mm256_srli_epi32(p, <span class="dv">1</span>);</a>
<a class="sourceLine" id="cb9-27" title="27">        }</a>
<a class="sourceLine" id="cb9-28" title="28"></a>
<a class="sourceLine" id="cb9-29" title="29">        _mm256_store_si256((__m256i*) &amp;results[i], res);</a>
<a class="sourceLine" id="cb9-30" title="30">    }</a>
<a class="sourceLine" id="cb9-31" title="31">}</a></code></pre></div>
<p>Эта реализация уже работает за 0.7 секунды — в 13.5 раз быстрее. При этом там и дальше есть, что оптимизировать.</p>
<h2 id="трудности-автовекторизации">Трудности автовекторизации</h2>
<p>В самом начале статьи мы приводили пример кода, в котором уже оптимизированный бинарник получается без каких-либо изменений, кроме подключения нужного таргета компиляции. Зачем тогда вообще программисту делать что-либо ещё?</p>
<p>Дело в том, что иногда — очень редко — программист всё-таки умнее компилятора, потому что знает про задачу чуть больше.</p>
<p>Рассмотрим этот же пример, убрав из него всё лишнее:</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb10-1" title="1"><span class="dt">void</span> sum(<span class="dt">int</span> a[], <span class="dt">int</span> b[], <span class="dt">int</span> c[], <span class="dt">int</span> n) {</a>
<a class="sourceLine" id="cb10-2" title="2">    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>)</a>
<a class="sourceLine" id="cb10-3" title="3">        c[i] = a[i] + b[i];</a>
<a class="sourceLine" id="cb10-4" title="4">}</a></code></pre></div>
<p>Почему эту функцию нельзя заменить на векторизованный-вариант автоматически?</p>
<p>Во-первых, потому что это не всегда корректно. Предположим, что <code>a[]</code> и <code>c[]</code> пересекаются, причём так, что указатели на начало массивов отличаются на 1-2 позиции. Ну, мало ли — может, мы такой изощрённой свёрткой хотели посчитать последовательность Фибоначчи. Тогда в simd-блоках данные будут пересекаться, и наблюдаемое поведение будет совсем не то, которое мы хотели.</p>
<p>Во-вторых, мы ничего не знаем про выравнивание этих массивов, и можем потерять производительность здесь (компилятор скорее всего сгенерирует инструкции с <code>loadu</code>).</p>
<p>На самом деле, когда компилятор подозревает, что функция будет использована для достаточно больших циклов, то на высоких уровнях оптимизации он сам вставит runtime-проверки на эти случаи и сгенерирует два разных варианта: через SSE и «безопасный».</p>
<p>Существуют <a href="https://software.intel.com/sites/default/files/m/4/8/8/2/a/31848-CompilerAutovectorizationGuide.pdf">различные способы</a> намекнуть компилятору, что конкретно мы имели в виду, но в сложных случаях — когда внутри цикла используются <code>if</code>-ы или вызываются какие-нибудь внешние функции — проще спуститься до уровня интринзиков и написать всё самому.</p>
<h2 id="разное">Разное</h2>
<p><strong>С++ в ассемблер.</strong> Посмотреть на генерируемые инструкции можно так:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode powershell"><code class="sourceCode powershell"><a class="sourceLine" id="cb11-1" title="1">g++ -S program.<span class="fu">cpp</span> -o program.<span class="fu">s</span></a></code></pre></div>
<p>Это позволяет понять, векторизует ли уже компилятор код или нет. Во многих IDE есть удобные плагины, позволяющие выяснять это для конкретных функций.</p>
<p><strong>Распечатать вектор.</strong> Для дебага помогает такой код:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb12-1" title="1"><span class="kw">template</span>&lt;<span class="kw">typename</span> T&gt;</a>
<a class="sourceLine" id="cb12-2" title="2"><span class="dt">void</span> print(T var) {</a>
<a class="sourceLine" id="cb12-3" title="3">    <span class="dt">unsigned</span> *val = (<span class="dt">unsigned</span>*) &amp;var;</a>
<a class="sourceLine" id="cb12-4" title="4">    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">4</span>; i++)</a>
<a class="sourceLine" id="cb12-5" title="5">        cout &lt;&lt; bitset&lt;<span class="dv">32</span>&gt;(val[i]) &lt;&lt; <span class="st">&quot; &quot;</span>;</a>
<a class="sourceLine" id="cb12-6" title="6">    cout &lt;&lt; endl;</a>
<a class="sourceLine" id="cb12-7" title="7">}</a></code></pre></div>
<p>В данном случае он выводит 4 группы по 32 бита из 128-битного вектора.</p>
<p><strong>Деление.</strong> В SSE нет операции деления <code>int</code>-ов, но есть для <code>float</code>-ов и производных. Также нет взятия остатка от деления, что осложняет вычисления в комбинаторике.</p>
<p>Для деления 32-битных целых чисел их можно аккуратно скастовать к даблу, поделить так, и скастовать обратно — точности хватит, хоть это и будет медленно.</p>
<p>Умножение работает в несколько раз быстрее деления, и поэтому для ускорения деления <code>float</code>-ов на известную константу <span class="math inline">\(d\)</span> есть следующий <a href="https://ridiculousfish.com/blog/posts/labor-of-division-episode-iii.html">трюк</a>: заменить выражение <span class="math inline">\(x / d\)</span> на <span class="math inline">\(x \cdot \frac{1}{d}\)</span>, и при этом <span class="math inline">\(\frac{1}{d}\)</span> посчитать во время компиляции.</p>
<p>Для целочисленных типов такое сделать немного сложнее — нужно заменить деление на умножение и битовый сдвиг. Для этого нужно приблизить <span class="math inline">\(\frac{1}{d} \approx \frac{m}{2^s}\)</span>, подобрав «магическое» число <span class="math inline">\(m\)</span> и степень двойки <span class="math inline">\(s\)</span>, такие что что <code>x / d == (x * m) &gt;&gt; s</code> для всех <code>x</code>.</p>
<p>Можно показать, что такая пара чисел всегда существует, и компилятор сам оптимизирует деление на константу подобным образом. Вот, например, сгенерированные инструкции для деления <code>unsigned long long</code> на <span class="math inline">\(10^9 + 7\)</span>:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode nasm"><code class="sourceCode nasm"><a class="sourceLine" id="cb13-1" title="1"><span class="kw">movq</span>    <span class="ot">%rdi, %rax</span></a>
<a class="sourceLine" id="cb13-2" title="2">movabsq    <span class="dv">$</span>-<span class="dv">8543223828751151131</span>, <span class="ot">%rdx ; загружает магическую константу в регистр</span></a>
<a class="sourceLine" id="cb13-3" title="3">mulq    <span class="ot">%rdx                        ; делает умножение</span></a>
<a class="sourceLine" id="cb13-4" title="4"><span class="kw">movq</span>    <span class="ot">%rdx, %rax</span></a>
<a class="sourceLine" id="cb13-5" title="5">shrq<span class="bn">    $29, </span><span class="ot">%rax                   ; делает битовый сдвиг результата</span></a></code></pre></div>
<p>Здесь для умножения используется «mixed precision» инструкция <code>mulq</code>, которая берёт два 64-битных числа и записывает 128-битный результат их умножения в два 64-битных регистра (lo, hi).</p>
<p>Для деления <code>long</code>-ов на SSE такой способ пока что не работает: аналогичная инструкция добавилась только в AVX512.</p>
</body>
</html>
