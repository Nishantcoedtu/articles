<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="" xml:lang="">
<head>
  <meta charset="utf-8" />
  <meta name="generator" content="pandoc" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes" />
  <title>Векторизация</title>
  <style>
      code{white-space: pre-wrap;}
      span.smallcaps{font-variant: small-caps;}
      span.underline{text-decoration: underline;}
      div.column{display: inline-block; vertical-align: top; width: 50%;}
  </style>
  <style>
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(title);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../pandoc.css" />
  <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-AMS_CHTML-full" type="text/javascript"></script>
  <!--[if lt IE 9]>
    <script src="//cdnjs.cloudflare.com/ajax/libs/html5shiv/3.7.3/html5shiv-printshiv.min.js"></script>
  <![endif]-->
  <link href="data:image/x-icon;base64,iVBORw0KGgoAAAANSUhEUgAAACAAAAAgCAQAAADZc7J/AAAABGdBTUEAALGPC/xhBQAAACBjSFJNAAB6JgAAgIQAAPoAAACA6AAAdTAAAOpgAAA6mAAAF3CculE8AAAAAmJLR0QA/4ePzL8AAAAJcEhZcwAACxMAAAsTAQCanBgAAAAHdElNRQfjBggQFxAS4ilBAAACgElEQVRIx52VS0iUYRSGn/8fzbxMIYoRKSZKi2wGwo2FxRQZIlGbaGUF0b52LWbTLlx0W7VyEZiBWkE5mraRRrJFRUwolQw6zQTeuoiU423eFuk0M//nhJ7dd+Z7n/8932HOscgIgU0lR/Cxn3LKgGlijDJIkAgJiywhZMujVo0qrsyIa1St8shWFnmp/IooW0TkV6mMYuRVQCv6X6woIK+QQ16vkPP2M/WZICHVpyGEvCb5vE7olH6bEV6l1R4w3RpQkYoVNJcSWHsLIUt+rTpvLOuSELqihAmwKr8sgZBHE2aX5UKoRmNmDxPyCBtoodLU1m5yaADC9Jr7XkkLoCqNmPAx1eqqnqhAqEHfzB5GVGXTQLUJ/5xZznGcOuAtQbOHahpsfOQ5f5mng8McZAdnsVigkyUTIA8fGjZ561OpuiRJY6oR2qU35iKGbSqc4GU6qObYmstmYIrH5iIq0JIT+17lupU8BVUsVKsvJgdLtgnbxXZOJ091HAU+0W+0YCnGnvRUlCa+42OdbRHiA3CSbtyZ+q85RDMBfcxxjZKUf5uPO4wwzGsaMwFR1JZe1Jx8uuB4mBtC6LJzXLTZDLKYihziM+fJzfjQGfYC/XxMTy8yaDNEOLWBDznAIcdT7aMRiPI0PR1myGacnn+Zd7ygiUIHwEUjuUAnsdR0D+M20E7k7/knt5ki39guN9uAEPeIr6citIPrOsxQiC9hveIuLylkkgXyKUsR/2CAB8yyEzdhJiliN3aCmzwCCwSl3FfzDL9wYZFAuClJAcSZJoELALFKAWVYvVxkdm3NbDRUs0TqUM021jeU15s2w9YXSxKy9dWWRGx6uVpOyObW+x/B+LEV0hF3cAAAACV0RVh0ZGF0ZTpjcmVhdGUAMjAxOS0wNi0wOFQxNjoyMzoxNiswMjowMLEfSBUAAAAldEVYdGRhdGU6bW9kaWZ5ADIwMTktMDYtMDhUMTY6MjM6MTYrMDI6MDDAQvCpAAAAV3pUWHRSYXcgcHJvZmlsZSB0eXBlIGlwdGMAAHic4/IMCHFWKCjKT8vMSeVSAAMjCy5jCxMjE0uTFAMTIESANMNkAyOzVCDL2NTIxMzEHMQHy4BIoEouAOoXEXTyQjWVAAAAAElFTkSuQmCC" rel="icon" type="image/x-icon" />
  
  <!-- Yandex.Metrika counter -->
  <script type="text/javascript">
     (function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};
     m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
     (window, document, "script", "https://mc.yandex.ru/metrika/tag.js", "ym");
  
     ym(53961409, "init", {
          clickmap:true,
          trackLinks:true,
          accurateTrackBounce:true,
          webvisor:true
     });
  </script>
  <noscript><div><img src="https://mc.yandex.ru/watch/53961409" style="position:absolute; left:-9999px;" alt="" /></div></noscript>
  <!-- /Yandex.Metrika counter -->
  
  <script>
  // index page width
  document.addEventListener("DOMContentLoaded", function(event) {
    document.getElementsByClassName('contents')[0].parentElement.style.width = "860px";
  });
  </script>
</head>
<body>
<header id="title-block-header">
<h1 class="title">Векторизация</h1>
</header>
<h1 id="векторизация">Векторизация</h1>
<p>Рассмотрим следующую программу, в которой складывают два массива:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb1-1" title="1"><span class="pp">#pragma GCC optimize(&quot;O3&quot;)</span></a>
<a class="sourceLine" id="cb1-2" title="2"><span class="co">// ^ включает самый &quot;агрессивный&quot; уровень оптимизации</span></a>
<a class="sourceLine" id="cb1-3" title="3"><span class="co">// то же самое, что добавить флаг &quot;-O3&quot; при компиляции из консоли</span></a>
<a class="sourceLine" id="cb1-4" title="4"><span class="pp">#include </span><span class="im">&lt;iostream&gt;</span></a>
<a class="sourceLine" id="cb1-5" title="5"></a>
<a class="sourceLine" id="cb1-6" title="6"><span class="at">const</span> <span class="dt">int</span> n = <span class="fl">1e6</span>;</a>
<a class="sourceLine" id="cb1-7" title="7"><span class="dt">int</span> a[n], b[n];</a>
<a class="sourceLine" id="cb1-8" title="8"></a>
<a class="sourceLine" id="cb1-9" title="9"><span class="dt">int</span> main() {</a>
<a class="sourceLine" id="cb1-10" title="10">    <span class="dt">int</span> s = <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb1-11" title="11">    <span class="co">// сложим всю сумму в &quot;где-то используемую&quot; переменную,</span></a>
<a class="sourceLine" id="cb1-12" title="12">    <span class="co">// иначе компилятор просто вырежет нужный нам кусок кода</span></a>
<a class="sourceLine" id="cb1-13" title="13"></a>
<a class="sourceLine" id="cb1-14" title="14">    <span class="cf">for</span> (<span class="dt">int</span> t = <span class="dv">0</span>; t &lt; <span class="dv">10000</span>; t++)</a>
<a class="sourceLine" id="cb1-15" title="15">        <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++)</a>
<a class="sourceLine" id="cb1-16" title="16">            s += a[i] + b[i];</a>
<a class="sourceLine" id="cb1-17" title="17"></a>
<a class="sourceLine" id="cb1-18" title="18">    <span class="bu">std::</span>cout &lt;&lt; s &lt;&lt; <span class="bu">std::</span>endl;</a>
<a class="sourceLine" id="cb1-19" title="19"></a>
<a class="sourceLine" id="cb1-20" title="20">    <span class="cf">return</span> <span class="dv">0</span>;</a>
<a class="sourceLine" id="cb1-21" title="21">}</a></code></pre></div>
<p>Если скомпилировать этот код под GCC без всяких дополнительных настроек и запустить, он отработает за 1.65 секунды.</p>
<p>Добавим теперь следующую магическую директиву в самое начало программы:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb2-1" title="1"><span class="pp">#pragma GCC target(&quot;avx2&quot;)</span></a>
<a class="sourceLine" id="cb2-2" title="2"><span class="co">// ...остальное в точности как было</span></a></code></pre></div>
<p>Скомпилировав и запустив при тех же условиях, программа завершается уже за 0.73 секунды. Это более чем в два раза быстрее, при том, что сам код и уровень оптимизации мы не меняли.</p>
<p>Чтобы понять, что здесь происходит, нам нужно сначала разъяснить некоторые особенности работы современных компьютеров.</p>
<h2 id="complex-instruction-set-computing">Complex Instruction Set Computing</h2>
<p>Раньше, во времена, когда компьютеры назывались ЭВМ-ами и занимали целую комнату, увеличение производительности происходило в основном за счёт увеличения тактовой частоты. Тактовая частота условно равна количеству инструкций, выполняемому процессором за единицу времени. (На современных процессорах <a href="http://ithare.com/infographics-operation-costs-in-cpu-clock-cycles/">это не так</a> — разные инструкции занимают разное время, которое ещё и может зависеть от разных обстоятельств.)</p>
<p>Помимо жесткого <a href="https://ru.wikipedia.org/wiki/%D0%A1%D0%BA%D0%BE%D1%80%D0%BE%D1%81%D1%82%D1%8C_%D1%81%D0%B2%D0%B5%D1%82%D0%B0">физического ограничения</a> на максимально возможную тактовую частоту, такой такой подход в какой-то момент просто перестал быть экономически оправданным: прямое увеличение тактовой частоты приводит к в более чем линейному потреблению энергии и выделению тепла, которое к тому же нужно как-то выводить.</p>
<p>Поэтому вендоры, в погоне за более дешёвым <a href="https://en.wikipedia.org/wiki/FLOPS">флопсом</a> за доллар, пошли по другому пути: стали добавлять более сложные инструкции, которые делают сразу много полезных действий за раз. Микросхема от добавления новых инструкций сильно усложняется, что становится критичным для многих других применениях. В связи с этим, все архитектуры стали делиться на два типа:</p>
<ul>
<li><p><a href="https://en.wikipedia.org/wiki/Reduced_instruction_set_computer">RISC</a> (англ. <strong>reduced</strong> instruction set computer), в которых длина кода (идентификатора) самой инструкции ограничена, а значит ограничено и само количество инструкций. Самые первые компьютеры относились к этому типу и могли не иметь даже отдельных инструкций для умножения и деления. Такие процессоры требует меньше транзисторов, и как следствие сами меньше, дешевле и потребляют меньше энергии. Самое популярное семейство архитектур называется <a href="https://en.wikipedia.org/wiki/ARM_architecture">arm</a> и используется почти на всех современных мобильных устройствах.</p></li>
<li><p><a href="https://en.wikipedia.org/wiki/Complex_instruction_set_computer">CISC</a> (англ. <strong>complex</strong> instruction set computer), к которому относят всё, что не RISC — в них длина команды не фиксирована, что позволяет поддерживать практически произовльное количество инструкций. Самоя популярное семейство архитектур называется <a href="https://en.wikipedia.org/wiki/X86">x86</a> и используется почти на всех современных декстопах и серверах.</p></li>
</ul>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/2a/Mips32_addi.svg/370px-Mips32_addi.svg.png" /></p>
<p>Новые инструкции стали добавлять постепенно, причём разные в зависимости от области применения.</p>
<ul>
<li><p>В общеприменимых CPU довольно быстро добавили инструкцию, которая принимает числа <span class="math inline">\((x, y)\)</span> и загружает в регистр данные по адресу <span class="math inline">\(a \cdot x + y\)</span>. Это полезно при индексации массивов — не нужно отдельно индекс считать.</p></li>
<li><p>На графических сопроцессорах появилась отдельная инструкция, которую называют «saxpy» (сокращенно от выражения <code>s += a * x + y</code>), которая полезна, например, при перемножении матриц.</p></li>
<li><p>В последние GPU от Nvidia добавили «tensor core» — отдельную схему, которая перемножает две матрицы <span class="math inline">\(4 \times 4\)</span> и прибавляет к третьей, как бы производя <span class="math inline">\(4 \times 4 \times 4 = 64\)</span> умножений и <span class="math inline">\(4 \times 4 = 16\)</span> сложений за раз, что сильно ускоряет алгоритмы <a href="https://en.wikipedia.org/wiki/Strassen_algorithm">блочного матричного умножения</a>.</p></li>
</ul>
<p>В этой статье мы сфокусируемся на отдельным виде инструкций, которые позволяют выполнять одну и ту же операцию сразу на какой-то последовательности данных. Эта концепция называется <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a>-параллелизмом (англ. <em>single instruction, multiple data</em>).</p>
<h2 id="streaming-simd-extensions">Streaming SIMD Extensions</h2>
<p>SSE — это обобщённое называние всех SIMD-инструкций для x86.</p>
<p>Работают они следующим образом. Помимо обычных регистров (самых близких к процессору ячеек памяти, с которыми он непосредственно работает), есть дополнительные, вмещающие не 64, а 128, 256 или даже 512 бит — в зависимости от поддерживаемой версии SSE. В эти регистры загружается последовательный блок из памяти, над ним производится какая-то последовательность операций, а итоговый результат записывается обратно в память. Сами операции обычно разбивают эту булеву последовательность на блоки, например, по 32 бит, и логически работают уже с ними.</p>
<p>Довольно легко получается оптимизировать простые циклы, производящие какие-нибудь независимые друг от друга операции над векторами (массивами) — поэтому сам такой подход называют <em>векторизацией</em>.</p>
<p>Например, какое-нибудь сложение двух int-овых массивов удаётся таким образом соптимизировать в <span class="math inline">\(\frac{512}{32} = 16\)</span> раз, если процессор поддерживает AVX512, а операции <a href="https://algorithmica.org/ru/bitset">битсета</a> — в 512 раз (реализация из STL, <a href="https://github.com/gcc-mirror/gcc/blob/master/libstdc%2B%2B-v3/include/std/bitset#L77">по всей видимости</a>, SSE не использует).</p>
<p>Очень часто SSE используют для работы с действительными числами, и вы этой ситуации возникает прямой trade-off между точностью вычислений и скоростью работы: например, вместо double можно использовать float, и тогда в один и тот же регистр поместится в два раза больше чисел. По этой причине в последнее время стали развиваться различные методы <a href="https://en.wikipedia.org/wiki/Quantization">квантизации</a>: перевода исходых данных в какой-то более дискретизированный формат на входе какой-нибудь процедуры (например, <a href="https://github.com/google/gemmlowp">матричного умножения</a>) и восстановления в исходный формат на выходе.</p>
<p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/2/21/SIMD.svg/1200px-SIMD.svg.png" /></p>
<p>Конкретный набор инструкций и размеры регистров зависит от вендора и поколения архитектуры. На данный момент (лето 2019 года) <a href="https://www.cpubenchmark.net/market_share.html">большинство процессоров</a> архитектуры x86 производит Intel, поэтому мы сконцентрируемся именно на их наборе инструкций.</p>
<p>Поддержка SIMD-инструкций добавлялись постепенно, сохраняя обратную совместимость. Если третий пентиум в 1999-м году умел работать с регистрами размера 128, то в самых современных i7 есть 512-битные регистры.</p>
<p><img src="https://i0.wp.com/www.urtech.ca/wp-content/uploads/2017/11/Intel-mmx-sse-sse2-avx-AVX-512.png" /></p>
<p>Чтобы разработчикам не нужно было предоставлять отдельные оптимизированные бинарники под каждую конкретную архитектуру, информация о поддержке наборов инструкций процессором зашита в ассемблерную инструкцию <code>cpuid</code>, которую можно просто вызвать в рантайме и всё узнать: <a href="https://gist.github.com/hi2p-perim/7855506">например так</a>.</p>
<p>В GCC есть встроенная функция <code>__builtin_cpu_supports</code>, которая берёт строчку-название набора инструкций (“sse”, “avx2”, “avx512f” и т. п.) и возвращает целое число — ноль или какую-то степень двойки. Эта функция работает так: входная строка во время компиляции переводится в нужную степень двойки, которая в рантайме просто AND-ится с маской из cpuid и возвращается — всё ради эффективности.</p>
<p>Экономя время читателю: сервера CodeForces и большинство онлайн джаджей на момент написания статьи поддерживают AVX2, то есть умеют работать с 256-битными регистрами.</p>
<h2 id="c-intrinsics">C++ intrinsics</h2>
<p>SSE это те же чистые ассемблерные инструкции. Языки с каким-либо более верхним <a href="https://en.wikipedia.org/wiki/Java_virtual_machine">уровнем абстракции</a> напрямую работать с ними уже не могут. Однако не обязательно писать на чистом ассемблере, чтобы их использовать — разработчики компиляторов уже позаботились об этом за вас и сделали встроенные функции-обёртки, которые называют <em>интринзиками</em> (англ. <em>intrinsic</em> — «внутренний»).</p>
<p>Чтобы их подключить, нужно указать <code>include</code> на соответствующий заголовочный файл, а также сказать компилятору о том, что мы хотим использовать конкретный набор или наборы инструкций. В примере из начала статьи мы сделали именно это, указав <code>target("avx2")</code> — компилятор получил доступ к более широким регистрам и продвинутым инструкциям для них, и смог соптимизировать программу примерно в два раза (по умолчанию включены 128-битные <code>sse</code> и <code>sse2</code>, поэтому в 2, а не в <span class="math inline">\(\frac{256}{32} = 8\)</span>).</p>
<p>По аналогии с <code>&lt;bits/stdc++.h&gt;</code>, в GCC такой же заголовочный файл <code>&lt;x86intrin.h&gt;</code>, включающий в себя сразу все SSE-интринзики. Шаблон любителя засоренных неймспейсов и избыточно долгой компиляции может начинаться так:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb3-1" title="1"><span class="pp">#pragma GCC optimize(&quot;O3&quot;)</span></a>
<a class="sourceLine" id="cb3-2" title="2"><span class="pp">#pragma GCC target(&quot;avx2&quot;)</span></a>
<a class="sourceLine" id="cb3-3" title="3"></a>
<a class="sourceLine" id="cb3-4" title="4"><span class="pp">#include </span><span class="im">&lt;x86intrin.h&gt;</span></a>
<a class="sourceLine" id="cb3-5" title="5"><span class="pp">#include </span><span class="im">&lt;bits/stdc++.h&gt;</span></a>
<a class="sourceLine" id="cb3-6" title="6"></a>
<a class="sourceLine" id="cb3-7" title="7"><span class="kw">using</span> <span class="kw">namespace</span> std;</a></code></pre></div>
<p>Простой цикл, в котором складывают два массива 64-битных действительных чисел, на SSE-интринзиках будет выглядеть так:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb4-1" title="1"><span class="dt">double</span> a[<span class="dv">100</span>], b[<span class="dv">100</span>], c[<span class="dv">100</span>];</a>
<a class="sourceLine" id="cb4-2" title="2"></a>
<a class="sourceLine" id="cb4-3" title="3"><span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">100</span>; i += <span class="dv">4</span>) {</a>
<a class="sourceLine" id="cb4-4" title="4">    <span class="co">// загрузим два отрезка по 256 бит в свои регистры</span></a>
<a class="sourceLine" id="cb4-5" title="5">    __m256d x = _mm256_loadu_pd(&amp;a[i]);</a>
<a class="sourceLine" id="cb4-6" title="6">    __m256d y = _mm256_loadu_pd(&amp;b[i]);</a>
<a class="sourceLine" id="cb4-7" title="7">    <span class="co">// - 256 означает размер регистров</span></a>
<a class="sourceLine" id="cb4-8" title="8">    <span class="co">// - d означает &quot;double&quot;</span></a>
<a class="sourceLine" id="cb4-9" title="9">    <span class="co">// - pd озанчает &quot;packed double&quot;</span></a>
<a class="sourceLine" id="cb4-10" title="10"></a>
<a class="sourceLine" id="cb4-11" title="11">    <span class="co">// просуммируем числа и положим результат в другой регистр:</span></a>
<a class="sourceLine" id="cb4-12" title="12">    __m256d z = _mm256_add_pd(x, y);</a>
<a class="sourceLine" id="cb4-13" title="13">    <span class="co">// запишем содержимое регистра в память:</span></a>
<a class="sourceLine" id="cb4-14" title="14">    _mm256_storeu_pd(&amp;c[i], z);</a>
<a class="sourceLine" id="cb4-15" title="15">}</a></code></pre></div>
<p>Конвенция именования интринзиков такая же, как самих инструкций, а она такая же, как в ассемблере — то есть максимально короткая и непонятная.</p>
<p>Большинство команд кодируются как <code>_mm&lt;размерность&gt;_&lt;действие&gt;_&lt;тип&gt;</code>. Например:</p>
<ul>
<li><p><code>_mm_add_epi16</code> — складывает две пачки 16-битных <em>extended packed integer</em>, проще говоря <span class="math inline">\(\frac{128}{16} = 8\)</span> <code>short</code>-ов (в инструкциях, где размер регистра не указан, он равен 128).</p></li>
<li><p><code>_mm256_acos_pd</code> — принимает один регистр, содержащий 4 <code>double</code>-ов, и возвращает их арк-косинусы.</p></li>
<li><p><code>_mm256_broadcast_sd</code> — бродкастит (копирует) <code>double</code> из памяти во все четыре слота в регистре.</p></li>
<li><p><code>_mm256_ceil_pd</code> — округляет <code>double</code> к ближайшему <code>int</code>-у вверх.</p></li>
</ul>
<p>Полная документация по SSE-интринзикам — <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics Guide</a> — лежит в закладках браузера у каждого уважающего себя performance engineer-а.</p>
<p><strong>Выравнивание.</strong> У операций чтения и записи есть по две версии: <code>load</code> / <code>loadu</code> и <code>store</code> / <code>storeu</code>. Буква «u» здесь означает «unaligned» (англ. невыровненный). Первая корректно работает только тогда, когда весь считываемый блок помещается на одну кэш-линию (в противном случае она вызывает segfault в рантайме), в то время как unaligned версия работает всегда и везде.</p>
<p>Это имело очень большое значение на старых компьютерах — если не получалось «выровнять» память, то производительность могла резко упасть (в два и более раз), потому что нарушался паттерн последовательного доступа. На современных компьютерах это не так значительно: будет медленне, но в пределах 5%. Вручную «выровнять» память для последовательного чтения через <code>load</code> в случае с массивами можно так:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb5-1" title="1"><span class="kw">alignas</span>(<span class="dv">32</span>) <span class="dt">int</span> a;</a>
<a class="sourceLine" id="cb5-2" title="2"><span class="co">// указатель на начало массива теперь будет кратен 32 байтам,</span></a>
<a class="sourceLine" id="cb5-3" title="3"><span class="co">// то есть размеру sse-блока; теперь любое чтение будет внутри кэш-линии</span></a>
<a class="sourceLine" id="cb5-4" title="4"></a>
<a class="sourceLine" id="cb5-5" title="5"><span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i += <span class="dv">8</span>) {</a>
<a class="sourceLine" id="cb5-6" title="6">    __m256i x = _mm256_load_epi32(&amp;a[i]);</a>
<a class="sourceLine" id="cb5-7" title="7">    <span class="co">// ...</span></a>
<a class="sourceLine" id="cb5-8" title="8">}</a></code></pre></div>
<p>Вообще, загружать и сохранять данные интринзиками и вообще использовать <code>__m</code>-типы на самом деле не обязательно — всё можно сделать и reinterpret_cast-ом. Все данные хранятся в одном и том же формате, и это просто нужно для проверки типов и избежания связанных ошибок.</p>
<h2 id="автовекторизация">Автовекторизация</h2>
<p>В самом начале статьи мы увидели пример, когда оптимальный результат был получен без какого-либо переписывания. Зачем вообще</p>
<p>Иногда — очень редко — программист всё-таки умнее компилятора и знает что-то больше.</p>
<p>На высоких уровнях оптимизации</p>
<p>Как мы убедились раньше, компилятор и без нас справляется оптимизировать циклы. Зачем вообще программисту что-либо делать, кроме подключения нужного таргета компиляции?</p>
<p>Обратите внимание, что . На старых компьютерах это было существенно (потеря производительности разница в более чем два раза), на современных же</p>
<h2 id="выравнивание">Выравнивание</h2>
<p>Ликбез о том, как работают кэши:</p>
<p>На самом деле, очень часто основным ограничением является работа памяти. Когда массив не будет помещаться в кэш, существенного ускорения уже не будет.</p>
<p>Ещё одна вещь, про которую нужно думать — это выравнивание (англ. <em>alignment</em>) в памяти.</p>
<h2 id="автовекторизация-1">Автовекторизация</h2>
<p>Почему компилятор сам это не делает?</p>
<p>В случае с сложением двух массивов может возникнуть такая проблема, что массивы пересекаются — мы ведь не знаем, что там находится.</p>
<p>Иногда компилятор просто-напросто не имеет достаточно информации, чтобы убедиться в корректности. Например, складываемые отрезки могут на самом деле пересекаться. При достаточно больших циклах на высоком уровне оптимизации компилятор сделает эту проверку прямо в рантайме, но в некоторых случаев этого не хватит.</p>
<p>От Intel есть гайд как оставлять намёки компилятору.</p>
<h2 id="на-контестах">На контестах</h2>
<p>Как правило, ограничение по времени в задачах подбирается следующим образом. Берётся решение жюри с оптимальной асимптотикой, берётся В задачах</p>
<h2 id="бинарное-возведение-в-степень">Бинарное возведение в степень</h2>
<div class="sourceCode" id="cb6"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb6-1" title="1"><span class="kw">typedef</span> <span class="dt">long</span> <span class="dt">long</span> ll;</a>
<a class="sourceLine" id="cb6-2" title="2"></a>
<a class="sourceLine" id="cb6-3" title="3"><span class="at">const</span> <span class="dt">int</span> mod = <span class="fl">1e9</span> + <span class="dv">7</span>;</a>
<a class="sourceLine" id="cb6-4" title="4"></a>
<a class="sourceLine" id="cb6-5" title="5"><span class="kw">inline</span> ll binpow(ll a, <span class="dt">int</span> n) {</a>
<a class="sourceLine" id="cb6-6" title="6">    ll res = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb6-7" title="7">    <span class="cf">while</span> (n &gt; <span class="dv">0</span>) {</a>
<a class="sourceLine" id="cb6-8" title="8">       <span class="cf">if</span> (n &amp; <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb6-9" title="9">           res = (res * a) % mod;</a>
<a class="sourceLine" id="cb6-10" title="10">       a = (a * a) % mod;</a>
<a class="sourceLine" id="cb6-11" title="11">       n &gt;&gt;= <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb6-12" title="12">    }</a>
<a class="sourceLine" id="cb6-13" title="13">    <span class="cf">return</span> res;</a>
<a class="sourceLine" id="cb6-14" title="14">}</a></code></pre></div>
<p>Возведём миллион (точнее, <span class="math inline">\(2^{20}\)</span>) чисел в степень:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb7-1" title="1"><span class="at">const</span> <span class="dt">int</span> n = (<span class="dv">1</span> &lt;&lt; <span class="dv">20</span>);</a>
<a class="sourceLine" id="cb7-2" title="2">ll a[n], p[n];</a>
<a class="sourceLine" id="cb7-3" title="3"></a>
<a class="sourceLine" id="cb7-4" title="4"><span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++) {</a>
<a class="sourceLine" id="cb7-5" title="5">    a[i] = rand();</a>
<a class="sourceLine" id="cb7-6" title="6">    p[i] = rand();</a>
<a class="sourceLine" id="cb7-7" title="7">}</a>
<a class="sourceLine" id="cb7-8" title="8"></a>
<a class="sourceLine" id="cb7-9" title="9"><span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; n; i++)</a>
<a class="sourceLine" id="cb7-10" title="10">    binpow(a[i], p[i]);</a></code></pre></div>
<p>Этот код работает за X секунд.</p>
<p>Для оптимизации, напишем sse-версию:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode cpp"><code class="sourceCode cpp"><a class="sourceLine" id="cb8-1" title="1"><span class="kw">inline</span> ll binpow_sse(reg a, reg n) {</a>
<a class="sourceLine" id="cb8-2" title="2">    ll res = <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb8-3" title="3">    <span class="co">// на самом деле, здесь никакого цикла не будет</span></a>
<a class="sourceLine" id="cb8-4" title="4">    <span class="co">// -- компилятор это раскроет в 30 отдельных операций для скорости</span></a>
<a class="sourceLine" id="cb8-5" title="5">    <span class="cf">for</span> (<span class="dt">int</span> i = <span class="dv">0</span>; i &lt; <span class="dv">30</span>; i++)</a>
<a class="sourceLine" id="cb8-6" title="6">        <span class="co">// посчитаем маску тех элементов, которые нужно домножать к res</span></a>
<a class="sourceLine" id="cb8-7" title="7"></a>
<a class="sourceLine" id="cb8-8" title="8">        <span class="co">// сделаем умножение и взятие по модулю</span></a>
<a class="sourceLine" id="cb8-9" title="9">        res = (res * a) % mod;</a>
<a class="sourceLine" id="cb8-10" title="10">        <span class="co">// возведём число a в квадрат, в любом случае</span></a>
<a class="sourceLine" id="cb8-11" title="11">        a = (a * a) % mod;</a>
<a class="sourceLine" id="cb8-12" title="12">        <span class="co">// сдвинем все показатели на один байт</span></a>
<a class="sourceLine" id="cb8-13" title="13">        n &gt;&gt;= <span class="dv">1</span>;</a>
<a class="sourceLine" id="cb8-14" title="14">    }</a>
<a class="sourceLine" id="cb8-15" title="15">    <span class="cf">return</span> res;</a>
<a class="sourceLine" id="cb8-16" title="16">}</a></code></pre></div>
<p>mixed precision</p>
</body>
</html>
